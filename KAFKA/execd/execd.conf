# Currently, no need in. Kafka is enough.
#[ZooKeeper] # Bindings to ZooKeeper cluster
# Cluster = ["ext-kafka.mhd.local","ext-kafka.ggs.local","ext-kafka.knk.local"]
# Timeout = 3
# xxx = ""  # With embedded TOML parser, unknown keys are silently ignored

[Kafka]
# Brokers must be SSL only. It's fundamental restriction for execd.
# Because all consumed messages are completelly trusted.
 Brokers = ["ext-kafka.xxx.local:9093", "ext-kafka.yyy.local:9093", "ext-kafka.zzz.local:9093"]
# CA certificate can be distributed with execd, in case it's inconvinient to import one into host's root CA's.
 caCertFile = "ca.pem"
# Client private key, together with CA-signed certificate.
# !!! Go don't have function to decrypt PKCS8 keys in standard library. !!!
# openssl default is PKCS8 pbeWITHMD5ndDES-CBC, while https://godoc.org/github.com/youmark/pkcs8 has AES-256-CBC only
# make(key&CSR): openssl req -x509 -new -passout pass:"samplePwd" -subj "/CN=linux-i0x0.mara.local" -days 36500 -outform PEM -out linux-i0x0.mara.local.csr -sha512 -newkey rsa:2048 -keyout key.pem
# test: openssl rsa -noout -text -in  key.pem
#
#openssl req -x509 -new -nodes  -sha512 -newkey rsa:2048 -keyout key.pem -subj "/CN=linux-i0x0.mara.local" -days 36500 -out /dev/null
#openssl req -new -key key.pem -out linux-i0x0.mara.local.csr -subj "/CN=linux-i0x0.mara.local"
#>>> openssl ca -config sign.config -in linux-i0x0.mara.local.csr -out linux-i0x0.mara.local.crt -batch

# privateKeyFile = "key.pem"
# privateKeyPassword = "XXXsamplePwd" # M.b. encoded. Not supported yet.
# certFile = "linux-i0x0.mara.local.crt"

# !!! In production, trusted root MUST be imported into the local storage !!!
# InsecureSkipVerify = true
# https://github.com/Shopify/sarama/blob/master/config.go
 ClientID = "" # defaults to host fqdn
 DialTimeout  = 10 # How long to wait for the initial connection.
 ReadTimeout  = 10 # How long to wait for a response.
 WriteTimeout = 10 # How long to wait for a transmit.
 KeepAlive = 30
# LocalAddr = "0.0.0.0" # Speak from this IP.

# kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 1 --topic "knot.test.xxx"
# kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 1 --topic "knot.test.yyy"
# kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 1 --topic "knot.test.zzz"
[Consume] # Must be RO for all consumers to avoid loops whith misconfig!!!
#    OffsetNewest int64 = -1
#    OffsetOldest int64 = -2
 Topics = ["knot.test", "knot.test.xxx"] # Bad idea to use multiple topics, it leads to problems in further debug!

# Partition = 1
# Where to save offsets. M.b. the good idea to store together with other state. To simplify backup/restore
 LocalDirectory = "/var/tmp/"

 FetchMax = 1048576 #  1MB is large enough. M.b. up to 256 MB messages due to hardcoded ChannelBufferSize!
 RetryBackoff = 10  # One retry per 10 seconds
 RetryMax = 8640 # !!! 10^4 takes about 1MB of RSS, because sarama fills some linear structure to do !!!

[Produce]
 Topic = "knot.log" # Single log for all agents
 Partition = 1
 # Where to save reports. Leave empty if there's no need in.
 LocalDirectory = "/var/tmp/reports"

 MaxMessageBytes = 16777216
 Timeout = 30
 RetryBackoff = 10
 RetryMax = 8640  # !!! 10^4 takes about 1MB of RSS, because sarama fills some linear structure to do !!!

[Hooks]
# Exec "Hooks.Start" just after catching up actual topics positions
# Therefore, the payload can be started after obtaining the actual state.
 Start = "/bin/date >> /tmp/HookStart"
# Exec "Hooks.Stop" during the regular shutdown (any cause, execept of SIGKILL)
 Stop = "/bin/date >> /tmp/HookStop"

# Store report to "Produce.Topic", like ordinary messages does.
 Produce = true
 Tag = "Hooks"
